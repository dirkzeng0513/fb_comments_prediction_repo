{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jingyang/yzeng/fb_comments_prediction/venv/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGB practice with FB comment data \n",
    "Date: 12/12/2020\n",
    "Author: Yan Zeng \n",
    "\n",
    "The note book is run under my project venv \n",
    "\n",
    "Some reference articles:\n",
    "https://janakiev.com/blog/jupyter-virtual-envs/\n",
    "https://towardsdatascience.com/create-virtual-environment-using-virtualenv-and-add-it-to-jupyter-notebook-6e1bf4e03415\n",
    "https://queirozf.com/entries/jupyter-kernels-how-to-add-change-remove\n",
    "\"\"\"\n",
    "\n",
    "import site\n",
    "# virtual environment in full function\n",
    "site.getsitepackages()\n",
    "\n",
    "# add project virtual environment to jupyter notebook (run under terminal to add venv to kernel list)\n",
    "# python3 -m ipykernel install --user --name=venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add packages from the same repo using relative path\n",
    "Need to add the upper \n",
    "\"\"\"\n",
    "import sys\n",
    "# show the default system path\n",
    "sys.path\n",
    "# add the upper level directory to the path\n",
    "sys.path.append(r'../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_function import loaddata\n",
    "from base_function import missingtreatment\n",
    "from base_function import parallelcomput\n",
    "from base_function import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'base_function.preprocessing' from '../base_function/preprocessing.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In ipython (\"Jupyter Notebook\"): after making changes to imported modules that create dependencies for the\\\n",
    "rest of the program, simply re-importing will not enable new changes\n",
    "Refer to the following read:\n",
    "https://support.enthought.com/hc/en-us/articles/204469240-Jupyter-IPython-After-editing-a-module-changes-are-not-effective-without-kernel-restart\n",
    "'''\n",
    "import importlib\n",
    "\n",
    "importlib.reload(loaddata)\n",
    "importlib.reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634995,0,463,1,0.0,806.0,11.291044776119403,1.0,70.49513846124168,0.0,806.0,7.574626865671642,0.0,69.435826365571,0.0,76.0,2.6044776119402986,0.0,8.50550186882253,0.0,806.0,10.649253731343284,1.0,70.25478763764251,-69.0,806.0,4.970149253731344,0.0,69.85058043098057,0,0,0,0,0,65,166,2,0,24,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0\n",
      "634995,0,463,1,0.0,806.0,11.291044776119403,1.0,70.49513846124168,0.0,806.0,7.574626865671642,0.0,69.435826365571,0.0,76.0,2.6044776119402986,0.0,8.50550186882253,0.0,806.0,10.649253731343284,1.0,70.25478763764251,-69.0,806.0,4.970149253731344,0.0,69.85058043098057,0,0,0,0,0,10,132,1,0,24,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0\n",
      "634995,0,463,1,0.0,806.0,11.291044776119403,1.0,70.49513846124168,0.0,806.0,7.574626865671642,0.0,69.435826365571,0.0,76.0,2.6044776119402986,0.0,8.50550186882253,0.0,806.0,10.649253731343284,1.0,70.25478763764251,-69.0,806.0,4.970149253731344,0.0,69.85058043098057,0,0,0,0,0,14,133,2,0,24,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0\n",
      "634995,0,463,1,0.0,806.0,11.291044776119403,1.0,70.49513846124168,0.0,806.0,7.574626865671642,0.0,69.435826365571,0.0,76.0,2.6044776119402986,0.0,8.50550186882253,0.0,806.0,10.649253731343284,1.0,70.25478763764251,-69.0,806.0,4.970149253731344,0.0,69.85058043098057,7,0,3,7,-3,62,131,1,0,24,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0\n",
      "634995,0,463,1,0.0,806.0,11.291044776119403,1.0,70.49513846124168,0.0,806.0,7.574626865671642,0.0,69.435826365571,0.0,76.0,2.6044776119402986,0.0,8.50550186882253,0.0,806.0,10.649253731343284,1.0,70.25478763764251,-69.0,806.0,4.970149253731344,0.0,69.85058043098057,1,0,0,1,0,58,142,5,0,24,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0\n",
      "@RELATION Train\n",
      "\n",
      "@ATTRIBUTE v[0] NUMERIC\n",
      "@ATTRIBUTE v[1] NUMERIC\n",
      "@ATTRIBUTE v[2] NUMERIC\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "load Facebook dataset \n",
    "\"\"\"\n",
    "!head -5 ../Dataset/Training/Features_Variant_1.csv\n",
    "!head -5 ../Dataset/Training/Features_Variant_1.arff\n",
    "csv_path = '../Dataset/Training/Features_Variant_1.csv'\n",
    "raw_data = loaddata.load_data(csv_path,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40933 entries, 0 to 40948\n",
      "Data columns (total 54 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       40933 non-null  int64  \n",
      " 1   1       40933 non-null  int64  \n",
      " 2   2       40933 non-null  int64  \n",
      " 3   3       40933 non-null  int64  \n",
      " 4   4       40933 non-null  float64\n",
      " 5   5       40933 non-null  float64\n",
      " 6   6       40933 non-null  float64\n",
      " 7   7       40933 non-null  float64\n",
      " 8   8       40933 non-null  float64\n",
      " 9   9       40933 non-null  float64\n",
      " 10  10      40933 non-null  float64\n",
      " 11  11      40933 non-null  float64\n",
      " 12  12      40933 non-null  float64\n",
      " 13  13      40933 non-null  float64\n",
      " 14  14      40933 non-null  float64\n",
      " 15  15      40933 non-null  float64\n",
      " 16  16      40933 non-null  float64\n",
      " 17  17      40933 non-null  float64\n",
      " 18  18      40933 non-null  float64\n",
      " 19  19      40933 non-null  float64\n",
      " 20  20      40933 non-null  float64\n",
      " 21  21      40933 non-null  float64\n",
      " 22  22      40933 non-null  float64\n",
      " 23  23      40933 non-null  float64\n",
      " 24  24      40933 non-null  float64\n",
      " 25  25      40933 non-null  float64\n",
      " 26  26      40933 non-null  float64\n",
      " 27  27      40933 non-null  float64\n",
      " 28  28      40933 non-null  float64\n",
      " 29  29      40933 non-null  int64  \n",
      " 30  30      40933 non-null  int64  \n",
      " 31  31      40933 non-null  int64  \n",
      " 32  32      40933 non-null  int64  \n",
      " 33  33      40933 non-null  int64  \n",
      " 34  34      40933 non-null  int64  \n",
      " 35  35      40933 non-null  int64  \n",
      " 36  36      40933 non-null  int64  \n",
      " 37  37      40933 non-null  int64  \n",
      " 38  38      40933 non-null  int64  \n",
      " 39  39      40933 non-null  int64  \n",
      " 40  40      40933 non-null  int64  \n",
      " 41  41      40933 non-null  int64  \n",
      " 42  42      40933 non-null  int64  \n",
      " 43  43      40933 non-null  int64  \n",
      " 44  44      40933 non-null  int64  \n",
      " 45  45      40933 non-null  int64  \n",
      " 46  46      40933 non-null  int64  \n",
      " 47  47      40933 non-null  int64  \n",
      " 48  48      40933 non-null  int64  \n",
      " 49  49      40933 non-null  int64  \n",
      " 50  50      40933 non-null  int64  \n",
      " 51  51      40933 non-null  int64  \n",
      " 52  52      40933 non-null  int64  \n",
      " 53  53      40933 non-null  int64  \n",
      "dtypes: float64(25), int64(29)\n",
      "memory usage: 17.2 MB\n",
      "the dataset has 40933 entries and 54 features\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()\n",
    "raw_data.sample(n=5)\n",
    "print(\"the dataset has {} entries and {} features\".format(*raw_data.shape)) # stared expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36839, 53)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "use scikit-learn train test split \n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = raw_data.loc[:,:52].values, raw_data.loc[:,53].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.1,random_state=41)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "loading data into DMatrices of Xgboost\n",
    "\"\"\"\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline prediction MAE is 10.003590532234874\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build a baseline model \n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# the mean of the training data\n",
    "mean_train = np.mean(y_train)\n",
    "\n",
    "# get the prediction of the test set\n",
    "baseline_prediction = np.ones(y_test.shape) * mean_train\n",
    "\n",
    "#compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_prediction)\n",
    "\n",
    "print(\"The baseline prediction MAE is {}\".format(mae_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.45484405, 7.45484405, 7.45484405, ..., 7.45484405, 7.45484405,\n",
       "       7.45484405])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "set up XGB hyperparameters\n",
    "\"\"\"\n",
    "params = {\n",
    "    # to tune the following parameters\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # other parameter\n",
    "    'objective': 'reg:squarederror',\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add additional parameters\n",
    "\"\"\"\n",
    "params['eval_metric'] = 'mae'\n",
    "\n",
    "# global config\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:12.09203\n",
      "[1]\tTest-mae:22.31347\n",
      "[2]\tTest-mae:42.67382\n",
      "[3]\tTest-mae:83.76589\n",
      "[4]\tTest-mae:167.75125\n",
      "[5]\tTest-mae:328.65970\n",
      "[6]\tTest-mae:656.27930\n",
      "[7]\tTest-mae:1277.37122\n",
      "[8]\tTest-mae:2534.96777\n",
      "[9]\tTest-mae:4998.37988\n",
      "[10]\tTest-mae:9909.55176\n",
      "[11]\tTest-mae:19598.96875\n",
      "[12]\tTest-mae:38854.16797\n",
      "[13]\tTest-mae:76970.82031\n",
      "[14]\tTest-mae:152497.06250\n",
      "Best MAE: 12.09 with 1 rounds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "first the first XGB model with default parameters\n",
    "\"\"\"\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest,'Test')],\n",
    "    early_stopping_rounds=15)\n",
    "\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\\\n",
    "                                              model.best_score,\n",
    "                                              model.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
      "0       14.299368       0.130327      14.934227      0.728926\n",
      "14.934226599999999\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use cross-validation to tune the hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=41,\n",
    "    nfold=5,\n",
    "    metrics=('mae'),\n",
    "    early_stopping_rounds=15\n",
    ")\n",
    "print(cv_results)\n",
    "print(cv_results['test-mae-mean'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run CV under grid search for \"max_depth\" and \"min_child_weight\"\n",
    "the ranges for the following two parameters could be much larger\n",
    "this is for demo purpose\n",
    "\"\"\"\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 5), (9, 6), (9, 7), (10, 5), (10, 6), (10, 7), (11, 5), (11, 6), (11, 7)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMAE14.6576476 for 0 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE14.5411316 for 0 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE14.551028400000002 for 0 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE14.4486248 for 0 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE14.323204800000003 for 0 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE14.345528400000001 for 0 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE14.3181726 for 0 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE14.2330984 for 0 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE14.300194600000001 for 0 rounds\n",
      "Best params: 11, 6, MAE: 14.2330984\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "run cv for the above combination\n",
    "\"\"\"\n",
    "# define initial best params and MAE\n",
    "min_mae = float('Inf')\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(max_depth,\n",
    "                                                             min_child_weight))\n",
    "    # update parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight']=min_child_weight\n",
    "    \n",
    "    # run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=41,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    \n",
    "    # update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE{} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    \n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params=(max_depth,min_child_weight)\n",
    "        \n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0],\n",
    "                                           best_params[1], min_mae))\n",
    "\n",
    "params['max_depth'] = best_params[0]\n",
    "params['min_child_weight'] = best_params[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run CV under grid search for \"subsample\" and \"colsample_bytree\"\n",
    "the ranges for the following two parameters could be much larger\n",
    "this is for demo purpose\n",
    "\"\"\"\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10 for i in range(7,11)]\n",
    "    for colsample in [i/10 for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "t\\MAE 14.2330984 for 0 rounds\n",
      "Best params: 1.0, 1.0. MAE: 14.2330984\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "t\\MAE 14.239598599999999 for 0 rounds\n",
      "Best params: 1.0, 1.0. MAE: 14.2330984\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "t\\MAE 14.215264000000001 for 0 rounds\n",
      "Best params: 1.0, 0.8. MAE: 14.215264000000001\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "t\\MAE 14.2494528 for 0 rounds\n",
      "Best params: 1.0, 0.8. MAE: 14.215264000000001\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "t\\MAE 14.1758722 for 0 rounds\n",
      "Best params: 0.9, 1.0. MAE: 14.1758722\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "t\\MAE 14.2877398 for 0 rounds\n",
      "Best params: 0.9, 1.0. MAE: 14.1758722\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "t\\MAE 14.117043 for 0 rounds\n",
      "Best params: 0.9, 0.8. MAE: 14.117043\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "t\\MAE 14.1254764 for 0 rounds\n",
      "Best params: 0.9, 0.8. MAE: 14.117043\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "t\\MAE 13.933536 for 0 rounds\n",
      "Best params: 0.8, 1.0. MAE: 13.933536\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "t\\MAE 14.011359199999998 for 0 rounds\n",
      "Best params: 0.8, 1.0. MAE: 13.933536\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "t\\MAE 13.844979599999998 for 0 rounds\n",
      "Best params: 0.8, 0.8. MAE: 13.844979599999998\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "t\\MAE 13.867880199999998 for 0 rounds\n",
      "Best params: 0.8, 0.8. MAE: 13.844979599999998\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "t\\MAE 13.608030600000001 for 0 rounds\n",
      "Best params: 0.7, 1.0. MAE: 13.608030600000001\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "t\\MAE 13.7922868 for 0 rounds\n",
      "Best params: 0.7, 1.0. MAE: 13.608030600000001\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "t\\MAE 13.9611446 for 0 rounds\n",
      "Best params: 0.7, 1.0. MAE: 13.608030600000001\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "t\\MAE 13.9840224 for 0 rounds\n",
      "Best params: 0.7, 1.0. MAE: 13.608030600000001\n"
     ]
    }
   ],
   "source": [
    "# Define initial MAE and best param \n",
    "min_mae = float('Inf')\n",
    "best_params = None\n",
    "\n",
    "# We start by the largest value and then go down to small ones\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print('CV with subsample={}, colsample={}'.format(subsample,\n",
    "                                                     colsample))\n",
    "    \n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=41,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=15)\n",
    "    \n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print('t\\MAE {} for {} rounds'.format(mean_mae, boost_rounds))\n",
    "    \n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample, colsample)\n",
    "        \n",
    "    print('Best params: {}, {}. MAE: {}'.format(best_params[0],\n",
    "                                               best_params[1], min_mae))\n",
    "    \n",
    "params['subsample'] = best_params[0]\n",
    "params['colsample_bytree'] = best_params[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.01 µs\n",
      "CV with eta=0.4\n",
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.25 µs\n",
      "\tMAE4.2542234 for 3 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "CPU times: user 29 µs, sys: 3 µs, total: 32 µs\n",
      "Wall time: 7.87 µs\n",
      "\tMAE3.9974054000000003 for 9 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: user 33 µs, sys: 1e+03 ns, total: 34 µs\n",
      "Wall time: 7.87 µs\n",
      "\tMAE3.9394988 for 19 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "CPU times: user 40 µs, sys: 2 µs, total: 42 µs\n",
      "Wall time: 9.3 µs\n",
      "\tMAE3.8606308 for 41 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "CPU times: user 38 µs, sys: 2 µs, total: 40 µs\n",
      "Wall time: 8.82 µs\n",
      "\tMAE3.8460493999999996 for 219 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "CPU times: user 29 µs, sys: 4 µs, total: 33 µs\n",
      "Wall time: 8.82 µs\n",
      "\tMAE3.819047 for 440 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "grid search for ETA (learning rate: shrinkage)\n",
    "\"\"\"\n",
    "%time\n",
    "\n",
    "min_mae = float('Inf')\n",
    "best_params = None\n",
    "\n",
    "for eta in [.4,.2, .1, .05, .01, .005]:\n",
    "    print('CV with eta={}'.format(eta))\n",
    "    \n",
    "    # Update parameters as shown above \n",
    "    params['eta'] = eta\n",
    "    \n",
    "    # Run and time CV\n",
    "    %time \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=41,\n",
    "        nfold=5,\n",
    "        metrics=['mae'],\n",
    "        early_stopping_rounds=15)\n",
    "    \n",
    "    # update results\n",
    "    mean_mae=cv_results['test-mae-mean'].min()\n",
    "    boost_rounds=cv_results['test-mae-mean'].argmin()\n",
    "    \n",
    "    print('\\tMAE{} for {} rounds\\n'.format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "        \n",
    "params['eta'] = best_params\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'min_child_weight': 6,\n",
       " 'eta': 0.005,\n",
       " 'subsample': 0.7,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'eval_metric': 'mae'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:6.18986\n",
      "[1]\tTest-mae:6.16331\n",
      "[2]\tTest-mae:6.13697\n",
      "[3]\tTest-mae:6.11121\n",
      "[4]\tTest-mae:6.08628\n",
      "[5]\tTest-mae:6.06012\n",
      "[6]\tTest-mae:6.03445\n",
      "[7]\tTest-mae:6.00826\n",
      "[8]\tTest-mae:5.98254\n",
      "[9]\tTest-mae:5.95833\n",
      "[10]\tTest-mae:5.93398\n",
      "[11]\tTest-mae:5.90925\n",
      "[12]\tTest-mae:5.88627\n",
      "[13]\tTest-mae:5.86258\n",
      "[14]\tTest-mae:5.83847\n",
      "[15]\tTest-mae:5.81481\n",
      "[16]\tTest-mae:5.79093\n",
      "[17]\tTest-mae:5.76693\n",
      "[18]\tTest-mae:5.74467\n",
      "[19]\tTest-mae:5.72187\n",
      "[20]\tTest-mae:5.69911\n",
      "[21]\tTest-mae:5.67595\n",
      "[22]\tTest-mae:5.65463\n",
      "[23]\tTest-mae:5.63250\n",
      "[24]\tTest-mae:5.61071\n",
      "[25]\tTest-mae:5.58868\n",
      "[26]\tTest-mae:5.56770\n",
      "[27]\tTest-mae:5.54522\n",
      "[28]\tTest-mae:5.52360\n",
      "[29]\tTest-mae:5.50093\n",
      "[30]\tTest-mae:5.48026\n",
      "[31]\tTest-mae:5.45813\n",
      "[32]\tTest-mae:5.43845\n",
      "[33]\tTest-mae:5.41729\n",
      "[34]\tTest-mae:5.39628\n",
      "[35]\tTest-mae:5.37511\n",
      "[36]\tTest-mae:5.35447\n",
      "[37]\tTest-mae:5.33482\n",
      "[38]\tTest-mae:5.31341\n",
      "[39]\tTest-mae:5.29381\n",
      "[40]\tTest-mae:5.27319\n",
      "[41]\tTest-mae:5.25340\n",
      "[42]\tTest-mae:5.23353\n",
      "[43]\tTest-mae:5.21400\n",
      "[44]\tTest-mae:5.19405\n",
      "[45]\tTest-mae:5.17357\n",
      "[46]\tTest-mae:5.15566\n",
      "[47]\tTest-mae:5.13710\n",
      "[48]\tTest-mae:5.11893\n",
      "[49]\tTest-mae:5.09968\n",
      "[50]\tTest-mae:5.08034\n",
      "[51]\tTest-mae:5.06154\n",
      "[52]\tTest-mae:5.04339\n",
      "[53]\tTest-mae:5.02586\n",
      "[54]\tTest-mae:5.00684\n",
      "[55]\tTest-mae:4.98909\n",
      "[56]\tTest-mae:4.97124\n",
      "[57]\tTest-mae:4.95373\n",
      "[58]\tTest-mae:4.93561\n",
      "[59]\tTest-mae:4.91845\n",
      "[60]\tTest-mae:4.90180\n",
      "[61]\tTest-mae:4.88421\n",
      "[62]\tTest-mae:4.86685\n",
      "[63]\tTest-mae:4.85040\n",
      "[64]\tTest-mae:4.83358\n",
      "[65]\tTest-mae:4.81662\n",
      "[66]\tTest-mae:4.80130\n",
      "[67]\tTest-mae:4.78498\n",
      "[68]\tTest-mae:4.76990\n",
      "[69]\tTest-mae:4.75562\n",
      "[70]\tTest-mae:4.74062\n",
      "[71]\tTest-mae:4.72492\n",
      "[72]\tTest-mae:4.70961\n",
      "[73]\tTest-mae:4.69412\n",
      "[74]\tTest-mae:4.67913\n",
      "[75]\tTest-mae:4.66462\n",
      "[76]\tTest-mae:4.65092\n",
      "[77]\tTest-mae:4.63686\n",
      "[78]\tTest-mae:4.62199\n",
      "[79]\tTest-mae:4.60813\n",
      "[80]\tTest-mae:4.59404\n",
      "[81]\tTest-mae:4.57989\n",
      "[82]\tTest-mae:4.56491\n",
      "[83]\tTest-mae:4.55063\n",
      "[84]\tTest-mae:4.53611\n",
      "[85]\tTest-mae:4.52262\n",
      "[86]\tTest-mae:4.50939\n",
      "[87]\tTest-mae:4.49631\n",
      "[88]\tTest-mae:4.48292\n",
      "[89]\tTest-mae:4.46894\n",
      "[90]\tTest-mae:4.45491\n",
      "[91]\tTest-mae:4.44240\n",
      "[92]\tTest-mae:4.42852\n",
      "[93]\tTest-mae:4.41599\n",
      "[94]\tTest-mae:4.40432\n",
      "[95]\tTest-mae:4.39247\n",
      "[96]\tTest-mae:4.37988\n",
      "[97]\tTest-mae:4.36895\n",
      "[98]\tTest-mae:4.35794\n",
      "[99]\tTest-mae:4.34580\n",
      "[100]\tTest-mae:4.33450\n",
      "[101]\tTest-mae:4.32222\n",
      "[102]\tTest-mae:4.30984\n",
      "[103]\tTest-mae:4.30032\n",
      "[104]\tTest-mae:4.28820\n",
      "[105]\tTest-mae:4.27855\n",
      "[106]\tTest-mae:4.26822\n",
      "[107]\tTest-mae:4.25698\n",
      "[108]\tTest-mae:4.24549\n",
      "[109]\tTest-mae:4.23493\n",
      "[110]\tTest-mae:4.22490\n",
      "[111]\tTest-mae:4.21520\n",
      "[112]\tTest-mae:4.20528\n",
      "[113]\tTest-mae:4.19540\n",
      "[114]\tTest-mae:4.18614\n",
      "[115]\tTest-mae:4.17592\n",
      "[116]\tTest-mae:4.16742\n",
      "[117]\tTest-mae:4.15828\n",
      "[118]\tTest-mae:4.14898\n",
      "[119]\tTest-mae:4.13901\n",
      "[120]\tTest-mae:4.12943\n",
      "[121]\tTest-mae:4.12025\n",
      "[122]\tTest-mae:4.11096\n",
      "[123]\tTest-mae:4.10145\n",
      "[124]\tTest-mae:4.09170\n",
      "[125]\tTest-mae:4.08291\n",
      "[126]\tTest-mae:4.07353\n",
      "[127]\tTest-mae:4.06557\n",
      "[128]\tTest-mae:4.05636\n",
      "[129]\tTest-mae:4.04784\n",
      "[130]\tTest-mae:4.03917\n",
      "[131]\tTest-mae:4.03047\n",
      "[132]\tTest-mae:4.02211\n",
      "[133]\tTest-mae:4.01382\n",
      "[134]\tTest-mae:4.00565\n",
      "[135]\tTest-mae:3.99692\n",
      "[136]\tTest-mae:3.98793\n",
      "[137]\tTest-mae:3.97984\n",
      "[138]\tTest-mae:3.97165\n",
      "[139]\tTest-mae:3.96456\n",
      "[140]\tTest-mae:3.95569\n",
      "[141]\tTest-mae:3.94765\n",
      "[142]\tTest-mae:3.94139\n",
      "[143]\tTest-mae:3.93421\n",
      "[144]\tTest-mae:3.92665\n",
      "[145]\tTest-mae:3.91853\n",
      "[146]\tTest-mae:3.91100\n",
      "[147]\tTest-mae:3.90297\n",
      "[148]\tTest-mae:3.89519\n",
      "[149]\tTest-mae:3.88898\n",
      "[150]\tTest-mae:3.88153\n",
      "[151]\tTest-mae:3.87406\n",
      "[152]\tTest-mae:3.86698\n",
      "[153]\tTest-mae:3.85980\n",
      "[154]\tTest-mae:3.85282\n",
      "[155]\tTest-mae:3.84551\n",
      "[156]\tTest-mae:3.83830\n",
      "[157]\tTest-mae:3.83256\n",
      "[158]\tTest-mae:3.82712\n",
      "[159]\tTest-mae:3.82136\n",
      "[160]\tTest-mae:3.81627\n",
      "[161]\tTest-mae:3.80857\n",
      "[162]\tTest-mae:3.80334\n",
      "[163]\tTest-mae:3.79727\n",
      "[164]\tTest-mae:3.79185\n",
      "[165]\tTest-mae:3.78567\n",
      "[166]\tTest-mae:3.77906\n",
      "[167]\tTest-mae:3.77291\n",
      "[168]\tTest-mae:3.76650\n",
      "[169]\tTest-mae:3.76039\n",
      "[170]\tTest-mae:3.75501\n",
      "[171]\tTest-mae:3.74864\n",
      "[172]\tTest-mae:3.74275\n",
      "[173]\tTest-mae:3.73639\n",
      "[174]\tTest-mae:3.73034\n",
      "[175]\tTest-mae:3.72528\n",
      "[176]\tTest-mae:3.72005\n",
      "[177]\tTest-mae:3.71529\n",
      "[178]\tTest-mae:3.71027\n",
      "[179]\tTest-mae:3.70611\n",
      "[180]\tTest-mae:3.70125\n",
      "[181]\tTest-mae:3.69766\n",
      "[182]\tTest-mae:3.69349\n",
      "[183]\tTest-mae:3.68894\n",
      "[184]\tTest-mae:3.68390\n",
      "[185]\tTest-mae:3.67905\n",
      "[186]\tTest-mae:3.67464\n",
      "[187]\tTest-mae:3.67018\n",
      "[188]\tTest-mae:3.66594\n",
      "[189]\tTest-mae:3.66123\n",
      "[190]\tTest-mae:3.65653\n",
      "[191]\tTest-mae:3.65202\n",
      "[192]\tTest-mae:3.64726\n",
      "[193]\tTest-mae:3.64232\n",
      "[194]\tTest-mae:3.63864\n",
      "[195]\tTest-mae:3.63584\n",
      "[196]\tTest-mae:3.63237\n",
      "[197]\tTest-mae:3.62917\n",
      "[198]\tTest-mae:3.62540\n",
      "[199]\tTest-mae:3.62195\n",
      "[200]\tTest-mae:3.61825\n",
      "[201]\tTest-mae:3.61383\n",
      "[202]\tTest-mae:3.61050\n",
      "[203]\tTest-mae:3.60643\n",
      "[204]\tTest-mae:3.60327\n",
      "[205]\tTest-mae:3.59880\n",
      "[206]\tTest-mae:3.59551\n",
      "[207]\tTest-mae:3.59160\n",
      "[208]\tTest-mae:3.58882\n",
      "[209]\tTest-mae:3.58550\n",
      "[210]\tTest-mae:3.58272\n",
      "[211]\tTest-mae:3.57961\n",
      "[212]\tTest-mae:3.57605\n",
      "[213]\tTest-mae:3.57237\n",
      "[214]\tTest-mae:3.56852\n",
      "[215]\tTest-mae:3.56527\n",
      "[216]\tTest-mae:3.56265\n",
      "[217]\tTest-mae:3.55985\n",
      "[218]\tTest-mae:3.55570\n",
      "[219]\tTest-mae:3.55395\n",
      "[220]\tTest-mae:3.55156\n",
      "[221]\tTest-mae:3.54773\n",
      "[222]\tTest-mae:3.54547\n",
      "[223]\tTest-mae:3.54245\n",
      "[224]\tTest-mae:3.53971\n",
      "[225]\tTest-mae:3.53709\n",
      "[226]\tTest-mae:3.53297\n",
      "[227]\tTest-mae:3.53068\n",
      "[228]\tTest-mae:3.52785\n",
      "[229]\tTest-mae:3.52501\n",
      "[230]\tTest-mae:3.52209\n",
      "[231]\tTest-mae:3.51965\n",
      "[232]\tTest-mae:3.51580\n",
      "[233]\tTest-mae:3.51355\n",
      "[234]\tTest-mae:3.51164\n",
      "[235]\tTest-mae:3.50806\n",
      "[236]\tTest-mae:3.50551\n",
      "[237]\tTest-mae:3.50302\n",
      "[238]\tTest-mae:3.49945\n",
      "[239]\tTest-mae:3.49751\n",
      "[240]\tTest-mae:3.49590\n",
      "[241]\tTest-mae:3.49297\n",
      "[242]\tTest-mae:3.49030\n",
      "[243]\tTest-mae:3.48793\n",
      "[244]\tTest-mae:3.48505\n",
      "[245]\tTest-mae:3.48304\n",
      "[246]\tTest-mae:3.48137\n",
      "[247]\tTest-mae:3.47970\n",
      "[248]\tTest-mae:3.47734\n",
      "[249]\tTest-mae:3.47461\n",
      "[250]\tTest-mae:3.47324\n",
      "[251]\tTest-mae:3.47182\n",
      "[252]\tTest-mae:3.46796\n",
      "[253]\tTest-mae:3.46547\n",
      "[254]\tTest-mae:3.46417\n",
      "[255]\tTest-mae:3.46230\n",
      "[256]\tTest-mae:3.46016\n",
      "[257]\tTest-mae:3.45889\n",
      "[258]\tTest-mae:3.45631\n",
      "[259]\tTest-mae:3.45398\n",
      "[260]\tTest-mae:3.45256\n",
      "[261]\tTest-mae:3.45008\n",
      "[262]\tTest-mae:3.44753\n",
      "[263]\tTest-mae:3.44522\n",
      "[264]\tTest-mae:3.44182\n",
      "[265]\tTest-mae:3.43987\n",
      "[266]\tTest-mae:3.43868\n",
      "[267]\tTest-mae:3.43734\n",
      "[268]\tTest-mae:3.43543\n",
      "[269]\tTest-mae:3.43353\n",
      "[270]\tTest-mae:3.43125\n",
      "[271]\tTest-mae:3.42936\n",
      "[272]\tTest-mae:3.42804\n",
      "[273]\tTest-mae:3.42674\n",
      "[274]\tTest-mae:3.42559\n",
      "[275]\tTest-mae:3.42412\n",
      "[276]\tTest-mae:3.42380\n",
      "[277]\tTest-mae:3.42271\n",
      "[278]\tTest-mae:3.42096\n",
      "[279]\tTest-mae:3.42052\n",
      "[280]\tTest-mae:3.41870\n",
      "[281]\tTest-mae:3.41738\n",
      "[282]\tTest-mae:3.41625\n",
      "[283]\tTest-mae:3.41483\n",
      "[284]\tTest-mae:3.41300\n",
      "[285]\tTest-mae:3.41132\n",
      "[286]\tTest-mae:3.41024\n",
      "[287]\tTest-mae:3.40887\n",
      "[288]\tTest-mae:3.40714\n",
      "[289]\tTest-mae:3.40652\n",
      "[290]\tTest-mae:3.40506\n",
      "[291]\tTest-mae:3.40409\n",
      "[292]\tTest-mae:3.40210\n",
      "[293]\tTest-mae:3.40050\n",
      "[294]\tTest-mae:3.39955\n",
      "[295]\tTest-mae:3.39751\n",
      "[296]\tTest-mae:3.39506\n",
      "[297]\tTest-mae:3.39331\n",
      "[298]\tTest-mae:3.39244\n",
      "[299]\tTest-mae:3.39078\n",
      "[300]\tTest-mae:3.38957\n",
      "[301]\tTest-mae:3.38916\n",
      "[302]\tTest-mae:3.38748\n",
      "[303]\tTest-mae:3.38701\n",
      "[304]\tTest-mae:3.38640\n",
      "[305]\tTest-mae:3.38568\n",
      "[306]\tTest-mae:3.38424\n",
      "[307]\tTest-mae:3.38377\n",
      "[308]\tTest-mae:3.38289\n",
      "[309]\tTest-mae:3.38156\n",
      "[310]\tTest-mae:3.38103\n",
      "[311]\tTest-mae:3.38121\n",
      "[312]\tTest-mae:3.38108\n",
      "[313]\tTest-mae:3.38085\n",
      "[314]\tTest-mae:3.37942\n",
      "[315]\tTest-mae:3.37910\n",
      "[316]\tTest-mae:3.37951\n",
      "[317]\tTest-mae:3.37882\n",
      "[318]\tTest-mae:3.37793\n",
      "[319]\tTest-mae:3.37813\n",
      "[320]\tTest-mae:3.37690\n",
      "[321]\tTest-mae:3.37611\n",
      "[322]\tTest-mae:3.37570\n",
      "[323]\tTest-mae:3.37493\n",
      "[324]\tTest-mae:3.37405\n",
      "[325]\tTest-mae:3.37341\n",
      "[326]\tTest-mae:3.37318\n",
      "[327]\tTest-mae:3.37300\n",
      "[328]\tTest-mae:3.37182\n",
      "[329]\tTest-mae:3.37081\n",
      "[330]\tTest-mae:3.36925\n",
      "[331]\tTest-mae:3.36859\n",
      "[332]\tTest-mae:3.36861\n",
      "[333]\tTest-mae:3.36807\n",
      "[334]\tTest-mae:3.36820\n",
      "[335]\tTest-mae:3.36766\n",
      "[336]\tTest-mae:3.36731\n",
      "[337]\tTest-mae:3.36674\n",
      "[338]\tTest-mae:3.36665\n",
      "[339]\tTest-mae:3.36644\n",
      "[340]\tTest-mae:3.36643\n",
      "[341]\tTest-mae:3.36551\n",
      "[342]\tTest-mae:3.36491\n",
      "[343]\tTest-mae:3.36383\n",
      "[344]\tTest-mae:3.36317\n",
      "[345]\tTest-mae:3.36378\n",
      "[346]\tTest-mae:3.36456\n",
      "[347]\tTest-mae:3.36411\n",
      "[348]\tTest-mae:3.36397\n",
      "[349]\tTest-mae:3.36352\n",
      "[350]\tTest-mae:3.36264\n",
      "[351]\tTest-mae:3.36187\n",
      "[352]\tTest-mae:3.36203\n",
      "[353]\tTest-mae:3.36194\n",
      "[354]\tTest-mae:3.36063\n",
      "[355]\tTest-mae:3.36080\n",
      "[356]\tTest-mae:3.36037\n",
      "[357]\tTest-mae:3.35987\n",
      "[358]\tTest-mae:3.36031\n",
      "[359]\tTest-mae:3.36012\n",
      "[360]\tTest-mae:3.36003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[361]\tTest-mae:3.35962\n",
      "[362]\tTest-mae:3.35901\n",
      "[363]\tTest-mae:3.35918\n",
      "[364]\tTest-mae:3.35889\n",
      "[365]\tTest-mae:3.35849\n",
      "[366]\tTest-mae:3.35854\n",
      "[367]\tTest-mae:3.35860\n",
      "[368]\tTest-mae:3.35837\n",
      "[369]\tTest-mae:3.35774\n",
      "[370]\tTest-mae:3.35795\n",
      "[371]\tTest-mae:3.35770\n",
      "[372]\tTest-mae:3.35757\n",
      "[373]\tTest-mae:3.35742\n",
      "[374]\tTest-mae:3.35803\n",
      "[375]\tTest-mae:3.35842\n",
      "[376]\tTest-mae:3.35868\n",
      "[377]\tTest-mae:3.35935\n",
      "[378]\tTest-mae:3.35980\n",
      "[379]\tTest-mae:3.35955\n",
      "[380]\tTest-mae:3.35914\n",
      "[381]\tTest-mae:3.35861\n",
      "[382]\tTest-mae:3.35890\n",
      "[383]\tTest-mae:3.36002\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now train the model with all optimized parameters\n",
    "\"\"\"\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, 'Test')],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 3.36 in 374 rounds\n"
     ]
    }
   ],
   "source": [
    "print('Best MAE: {:,.2f} in {} rounds'.format(model.best_score, model.best_iteration+1))\n",
    "params{'num'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fix num_boos\n",
    "\"\"\"\n",
    "params['num_boost_round'] = model.best_iteration+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:54:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { num_boost_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tTest-mae:6.18986\n",
      "[1]\tTest-mae:6.16331\n",
      "[2]\tTest-mae:6.13697\n",
      "[3]\tTest-mae:6.11121\n",
      "[4]\tTest-mae:6.08628\n",
      "[5]\tTest-mae:6.06012\n",
      "[6]\tTest-mae:6.03445\n",
      "[7]\tTest-mae:6.00826\n",
      "[8]\tTest-mae:5.98254\n",
      "[9]\tTest-mae:5.95833\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "save model file \n",
    "\"\"\"\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    evals=[(dtest, 'Test')])\n",
    "\n",
    "best_model.save_model('final_fb_comment_pred.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way to save the model is to save it as a JSON file\n",
    "with open (r'../final_model/final_fb_comments_xgb.json','w') as file:\n",
    "    best_model.save_model('final_fb_comment_pred.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { num_boost_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tTest-mae:6.18986\n",
      "[1]\tTest-mae:6.16331\n",
      "[2]\tTest-mae:6.13697\n",
      "[3]\tTest-mae:6.11121\n",
      "[4]\tTest-mae:6.08628\n",
      "[5]\tTest-mae:6.06012\n",
      "[6]\tTest-mae:6.03445\n",
      "[7]\tTest-mae:6.00826\n",
      "[8]\tTest-mae:5.98254\n",
      "[9]\tTest-mae:5.95833\n"
     ]
    }
   ],
   "source": [
    "# or to use JSON to store memory snapshots, add enable_experimental_json_serialization as a training parameter. In Python this can be done by:\n",
    "import pickle\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    evals=[(dtest, 'Test')])\n",
    "with open(r'../final_model/final_fb_comments_xgb.pkl', 'wb') as fd:\n",
    "    pickle.dump(best_model, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { num_boost_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tTest-mae:6.18986\n",
      "[1]\tTest-mae:6.16331\n",
      "[2]\tTest-mae:6.13697\n",
      "[3]\tTest-mae:6.11121\n",
      "[4]\tTest-mae:6.08628\n",
      "[5]\tTest-mae:6.06012\n",
      "[6]\tTest-mae:6.03445\n",
      "[7]\tTest-mae:6.00826\n",
      "[8]\tTest-mae:5.98254\n",
      "[9]\tTest-mae:5.95833\n"
     ]
    }
   ],
   "source": [
    "# or to use JSON to store memory snapshots, add enable_experimental_json_serialization as a training parameter. In Python this can be done by:\n",
    "import json\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    evals=[(dtest, 'Test')])\n",
    "with open(r'../final_model/final_fb_comments_xgb.json', 'wb') as fd:\n",
    "    pickle.dump(best_model, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
